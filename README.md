# Dynamic Minority Amplification and Fuzzy Fusion for Real-Time Stress Detection  
**Multimodal Stress Detection from Facial and Vocal Cues**

## Abstract  
This project presents a real-time multimodal stress detection system that combines facial expression analysis and speech emotion recognition using deep learning models and fuzzy fusion.  
The goal is to accurately detect psychological stress for mental health monitoring and workplace well-being.

## Motivation  
Stress detection using a single modality is unreliable.  
This work improves robustness by combining facial and vocal cues using fuzzy logic and addressing class imbalance through Dynamic Minority Amplification.

## Contributions  
- Facial emotion recognition model  
- Speech emotion recognition model  
- Dynamic Minority Amplification for class imbalance  
- Fuzzy fusion for multimodal stress detection  
- Real-time stress monitoring pipeline  

## Repository Structure
face_model/ → Facial expression model
audio_model/ → Speech emotion model
fusion_realtime/ → Multimodal fusion & real-time system


## How to Run  
1. Clone the repository  
2. Install dependencies  
3. Run notebooks in this order:
   - face_model/01_Facial_Expression_Model.ipynb  
   - audio_model/02_Audio_Emotion_Model.ipynb  
   - fusion_realtime/03_Fusion_RealTime_System.ipynb  

## Author  
**P. Krishna Vamsi**  
GitHub: https://github.com/Vamsi12022003
